{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "<h3>The following implementation of PRADO is taken from this source:<h3>\n",
        "<table class=\"tfo-notebook-buttons\" align=\"left\">\n",
        "  <td>\n",
        "    <a target=\"_blank\" href=\"https://github.com/tensorflow/models/blob/master/research/seq_flow_lite/demo/colab/emotion_colab.ipynb\"><img src=\"https://www.tensorflow.org/images/GitHub-Mark-32px.png\" />View source on GitHub</a>\n",
        "</table>"
      ],
      "metadata": {
        "id": "tpB-uix5r21b"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "PHNLbLFhf479"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "\n",
        "import tensorflow_datasets as tfds\n",
        "from tensorflow.keras.models import load_model\n",
        "import matplotlib.pyplot as plt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_Qf80EJ3WKl1",
        "outputId": "86e3a685-fd5a-4020-ea24-9f4a820c0f83"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/gdrive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "N_1Q2GPR-h0_"
      },
      "source": [
        "Install Bazel: This will allow us to build custom TensorFlow ops used by the PRADO architecture."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bCoZNr0x-g_9",
        "outputId": "e4a9a08b-0b56-43d6-e404-85414f5d6a4f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Reading package lists... Done\n",
            "Building dependency tree       \n",
            "Reading state information... Done\n",
            "curl is already the newest version (7.68.0-1ubuntu2.16).\n",
            "gnupg is already the newest version (2.2.19-3ubuntu2.2).\n",
            "gnupg set to manually installed.\n",
            "0 upgraded, 0 newly installed, 0 to remove and 22 not upgraded.\n",
            "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
            "                                 Dload  Upload   Total   Spent    Left  Speed\n",
            "100  4714  100  4714    0     0  19240      0 --:--:-- --:--:-- --:--:-- 19240\n",
            "OK\n",
            "deb [arch=amd64] https://storage.googleapis.com/bazel-apt stable jdk1.8\n",
            "Get:1 https://cloud.r-project.org/bin/linux/ubuntu focal-cran40/ InRelease [3,622 B]\n",
            "Ign:2 https://developer.download.nvidia.com/compute/machine-learning/repos/ubuntu2004/x86_64  InRelease\n",
            "Hit:3 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2004/x86_64  InRelease\n",
            "Hit:4 https://developer.download.nvidia.com/compute/machine-learning/repos/ubuntu2004/x86_64  Release\n",
            "Hit:5 http://archive.ubuntu.com/ubuntu focal InRelease\n",
            "Get:7 http://security.ubuntu.com/ubuntu focal-security InRelease [114 kB]\n",
            "Hit:8 http://ppa.launchpad.net/c2d4u.team/c2d4u4.0+/ubuntu focal InRelease\n",
            "Get:9 https://storage.googleapis.com/bazel-apt stable InRelease [2,256 B]\n",
            "Get:10 http://archive.ubuntu.com/ubuntu focal-updates InRelease [114 kB]\n",
            "Get:11 https://storage.googleapis.com/bazel-apt stable/jdk1.8 amd64 Packages [8,889 B]\n",
            "Hit:12 http://ppa.launchpad.net/cran/libgit2/ubuntu focal InRelease\n",
            "Get:13 http://security.ubuntu.com/ubuntu focal-security/universe amd64 Packages [1,012 kB]\n",
            "Get:14 http://archive.ubuntu.com/ubuntu focal-backports InRelease [108 kB]\n",
            "Hit:15 http://ppa.launchpad.net/deadsnakes/ppa/ubuntu focal InRelease\n",
            "Get:16 http://archive.ubuntu.com/ubuntu focal-updates/restricted amd64 Packages [2,134 kB]\n",
            "Hit:17 http://ppa.launchpad.net/graphics-drivers/ppa/ubuntu focal InRelease\n",
            "Get:18 http://security.ubuntu.com/ubuntu focal-security/main amd64 Packages [2,535 kB]\n",
            "Hit:19 http://ppa.launchpad.net/ubuntugis/ppa/ubuntu focal InRelease\n",
            "Get:20 http://archive.ubuntu.com/ubuntu focal-updates/universe amd64 Packages [1,308 kB]\n",
            "Get:21 http://security.ubuntu.com/ubuntu focal-security/restricted amd64 Packages [1,998 kB]\n",
            "Get:22 http://archive.ubuntu.com/ubuntu focal-updates/main amd64 Packages [3,012 kB]\n",
            "Get:23 http://archive.ubuntu.com/ubuntu focal-updates/multiverse amd64 Packages [31.3 kB]\n",
            "Fetched 12.4 MB in 3s (3,599 kB/s)\n",
            "Reading package lists... Done\n",
            "Building dependency tree       \n",
            "Reading state information... Done\n",
            "25 packages can be upgraded. Run 'apt list --upgradable' to see them.\n",
            "Reading package lists... Done\n",
            "Building dependency tree       \n",
            "Reading state information... Done\n",
            "Suggested packages:\n",
            "  bash-completion\n",
            "The following NEW packages will be installed:\n",
            "  bazel\n",
            "0 upgraded, 1 newly installed, 0 to remove and 25 not upgraded.\n",
            "Need to get 48.6 MB of archives.\n",
            "After this operation, 0 B of additional disk space will be used.\n",
            "Get:1 https://storage.googleapis.com/bazel-apt stable/jdk1.8 amd64 bazel amd64 5.4.0 [48.6 MB]\n",
            "Fetched 48.6 MB in 3s (18.2 MB/s)\n",
            "debconf: unable to initialize frontend: Dialog\n",
            "debconf: (No usable dialog-like program is installed, so the dialog based frontend cannot be used. at /usr/share/perl5/Debconf/FrontEnd/Dialog.pm line 76, <> line 1.)\n",
            "debconf: falling back to frontend: Readline\n",
            "debconf: unable to initialize frontend: Readline\n",
            "debconf: (This frontend requires a controlling tty.)\n",
            "debconf: falling back to frontend: Teletype\n",
            "dpkg-preconfigure: unable to re-open stdin: \n",
            "Selecting previously unselected package bazel.\n",
            "(Reading database ... 128213 files and directories currently installed.)\n",
            "Preparing to unpack .../archives/bazel_5.4.0_amd64.deb ...\n",
            "Unpacking bazel (5.4.0) ...\n",
            "Setting up bazel (5.4.0) ...\n"
          ]
        }
      ],
      "source": [
        "!sudo apt install curl gnupg\n",
        "!curl https://bazel.build/bazel-release.pub.gpg | sudo apt-key add -\n",
        "!echo \"deb [arch=amd64] https://storage.googleapis.com/bazel-apt stable jdk1.8\" | sudo tee /etc/apt/sources.list.d/bazel.list\n",
        "!sudo apt update\n",
        "!sudo apt install bazel=5.4.0"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tn5HK97X-s9r"
      },
      "source": [
        "Install the library:\n",
        "* `seq_flow_lite` includes the PRADO architecture and custom ops.\n",
        "* We download the code from GitHub, and then build and install the TF and TFLite ops used by the model."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6k2tVX5k-uuI",
        "outputId": "a46a1248-bdcf-4daf-c578-039544c53a56"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'models'...\n",
            "warning: redirecting to https://github.com/tensorflow/models.git/\n",
            "remote: Enumerating objects: 81861, done.\u001b[K\n",
            "remote: Counting objects: 100% (328/328), done.\u001b[K\n",
            "remote: Compressing objects: 100% (171/171), done.\u001b[K\n",
            "remote: Total 81861 (delta 197), reused 261 (delta 157), pack-reused 81533\u001b[K\n",
            "Receiving objects: 100% (81861/81861), 596.30 MiB | 23.17 MiB/s, done.\n",
            "Resolving deltas: 100% (58396/58396), done.\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Processing ./models/research/seq_flow_lite\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Building wheels for collected packages: seq-flow-lite\n",
            "  Building wheel for seq-flow-lite (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for seq-flow-lite: filename=seq_flow_lite-0.1-py3-none-any.whl size=758969 sha256=6431614366f98ec7cdd0798861e636cd15521648fd4981013a0bf9e8aea113d9\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-86hpp65n/wheels/eb/52/28/00d5797353c4a3a35688718d809124dd994ea8487cb7676fba\n",
            "Successfully built seq-flow-lite\n",
            "Installing collected packages: seq-flow-lite\n",
            "Successfully installed seq-flow-lite-0.1\n"
          ]
        }
      ],
      "source": [
        "!git clone https://www.github.com/tensorflow/models\n",
        "!models/research/seq_flow_lite/demo/colab/setup_workspace.sh\n",
        "!pip install models/research/seq_flow_lite\n",
        "!rm -rf models/research/seq_flow_lite/tf_ops\n",
        "!rm -rf models/research/seq_flow_lite/tflite_ops"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tbWhxqwGbVLE",
        "outputId": "e331559c-5d33-40f4-facb-94da2f4d5a3b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/models/research/seq_flow_lite\n"
          ]
        }
      ],
      "source": [
        "%cd /content/models/research/seq_flow_lite"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3flkR_k-_E3f"
      },
      "source": [
        "labels which the multi labelled prado model."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "qG8AXxAS_DHL"
      },
      "outputs": [],
      "source": [
        "LABELS = [\n",
        "    'admiration',\n",
        "    'amusement',\n",
        "    'anger',\n",
        "    'annoyance',\n",
        "    'approval',\n",
        "    'caring',\n",
        "    'confusion',\n",
        "    'curiosity',\n",
        "    'desire',\n",
        "    'disappointment',\n",
        "    'disapproval',\n",
        "    'disgust',\n",
        "    'embarrassment',\n",
        "    'excitement',\n",
        "    'fear',\n",
        "    'gratitude',\n",
        "    'grief',\n",
        "    'joy',\n",
        "    'love',\n",
        "    'nervousness',\n",
        "    'optimism',\n",
        "    'pride',\n",
        "    'realization',\n",
        "    'relief',\n",
        "    'remorse',\n",
        "    'sadness',\n",
        "    'surprise',\n",
        "    'neutral',\n",
        "]\n",
        "\n",
        "MODEL_CONFIG = {\n",
        "    'labels': LABELS,\n",
        "    'multilabel': True,\n",
        "    'quantize': False,\n",
        "    'max_seq_len': 128,\n",
        "    'max_seq_len_inference': 128,\n",
        "    'exclude_nonalphaspace_unicodes': False,\n",
        "    'split_on_space': True,\n",
        "    'embedding_regularizer_scale': 0.035,\n",
        "    'embedding_size': 64,\n",
        "    'bigram_channels': 64,\n",
        "    'trigram_channels': 64,\n",
        "    'feature_size': 512,\n",
        "    'network_regularizer_scale': 0.0001,\n",
        "    'keep_prob': 0.5,\n",
        "    'word_novelty_bits': 0,\n",
        "    'doc_size_levels': 0,\n",
        "    'add_bos_tag': False,\n",
        "    'add_eos_tag': False,\n",
        "    'pre_logits_fc_layers': [],\n",
        "    'text_distortion_probability': 0.0,\n",
        "}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "Drj7xY7o-1T4"
      },
      "outputs": [],
      "source": [
        "from layers import base_layers\n",
        "from models import prado\n",
        "from layers import projection_layers\n",
        "\n",
        "def build_model(mode):\n",
        "  # First we define our inputs.\n",
        "  inputs = []\n",
        "  if mode == base_layers.TRAIN or mode == base_layers.EVAL:\n",
        "    # For TRAIN and EVAL, we'll be getting dataset examples,\n",
        "    # so we'll get projections and sequence_lengths.\n",
        "    projection = tf.keras.Input(\n",
        "        shape=(MODEL_CONFIG['max_seq_len'], MODEL_CONFIG['feature_size']),\n",
        "        name='projection',\n",
        "        dtype='float32')\n",
        "\n",
        "    sequence_length = tf.keras.Input(\n",
        "        shape=(), name='sequence_length', dtype='float32')\n",
        "    inputs = [projection, sequence_length]\n",
        "  else:\n",
        "    # Otherwise, we get string inputs which we need to project.\n",
        "    input = tf.keras.Input(shape=(), name='input', dtype='string')\n",
        "    projection_layer = projection_layers.ProjectionLayer(MODEL_CONFIG, mode)\n",
        "    projection, sequence_length = projection_layer(input)\n",
        "    inputs = [input]\n",
        "\n",
        "  # Next we add the model layer.\n",
        "  model_layer = prado.Encoder(MODEL_CONFIG, mode)\n",
        "  logits = model_layer(projection, sequence_length)\n",
        "\n",
        "  # Finally we add an activation layer.\n",
        "  if MODEL_CONFIG['multilabel']:\n",
        "    activation = tf.keras.layers.Activation('sigmoid', name='predictions')\n",
        "  else:\n",
        "    activation = tf.keras.layers.Activation('softmax', name='predictions')\n",
        "  predictions = activation(logits)\n",
        "\n",
        "  model = tf.keras.Model(\n",
        "      inputs=inputs,\n",
        "      outputs=[predictions])\n",
        "  \n",
        "  return model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jHOrjd_aHbwh"
      },
      "source": [
        "Loading the model for model weights and running inference for the selected examples:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5mXOzL47DLnh",
        "outputId": "5a933945-fa93-4526-b27c-9c5431935d46"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.8/dist-packages/tensorflow/python/autograph/pyct/static_analysis/liveness.py:83: Analyzer.lamba_check (from tensorflow.python.autograph.pyct.static_analysis.liveness) is deprecated and will be removed after 2023-09-23.\n",
            "Instructions for updating:\n",
            "Lambda fuctions will be no more assumed to be used in the statement where they are used, or at least in the same block. https://github.com/tensorflow/tensorflow/issues/56089\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.checkpoint.checkpoint.CheckpointLoadStatus at 0x7f799c609580>"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ],
      "source": [
        "model = build_model(base_layers.PREDICT)\n",
        "model.load_weights('/content/gdrive/MyDrive/model_weights/model_checkpoint')"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Training a KMeans clustering algorithm with 250 top [Hollywood movies](https://www.imdb.com/chart/top-english-movies/)"
      ],
      "metadata": {
        "id": "WOwemLsnKGJR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%cd /content/gdrive/MyDrive/movie_recommender"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jB7cMR77oKnl",
        "outputId": "0e8dca4b-0cbd-4b36-9304-cd71dfea85ab"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/gdrive/MyDrive/movie_recommender\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from imdb_scraper import *\n",
        "from recommender import reviews_to_sent , get_mov_ranked , preprocess , GENRES"
      ],
      "metadata": {
        "id": "QuAyQzLXDjkM"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create a pandas dataframe containing the movie and genres.\n",
        "df = pd.read_csv('movies.csv')\n",
        "\n",
        "# representing the genres of each movie in a sparse \n",
        "df = df.assign(**{genre: 0 for genre in GENRES})"
      ],
      "metadata": {
        "id": "Idihho7boVnI"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df = df.sample(500)"
      ],
      "metadata": {
        "id": "I9PuhYhPw8uq"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "preprocessed_df = preprocess(df, 'preprocessed_df.csv', model, tokenized=True, count=5)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2SiZPX7mos_I",
        "outputId": "6c4a9e78-e1b5-4176-aaea-fdc21381c06d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 76%|███████▋  | 382/500 [45:38<15:40,  7.97s/it]"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "mask = preprocessed_df['sentiment'].apply(lambda x: isinstance(x, np.ndarray) and x.shape == (28,))\n",
        "preprocessed_df = preprocessed_df[mask]"
      ],
      "metadata": {
        "id": "NTUWTfIF-_Si"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Movie Recommendation for the 2021 Movie [Nobody](https://www.imdb.com/title/tt7888964/?ref_=tt_urv) and similarity between sentiment labels of prediction and movies from the vector space using cosine similarity metric"
      ],
      "metadata": {
        "id": "CvkecrrPJ19j"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "movie=\"Nobody\""
      ],
      "metadata": {
        "id": "dy-s67rT_De6"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "recommended_movies = get_mov_ranked(preprocessed_df , movie , model , tokenizer=None , mov_count=10)"
      ],
      "metadata": {
        "id": "wrud6_Ik_Ey0"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Recommended Movies: \")\n",
        "for mov in recommended_movies:\n",
        "  print(mov)"
      ],
      "metadata": {
        "id": "xNoVteHpAMA1",
        "outputId": "e5e2f1d6-02e4-4f85-d511-d6c045a9e305",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Recommended Movies: \n",
            "47  Ronin (Shijûshichinin no shikaku) (1994)\n",
            "Black Rain (1989)\n",
            "Paris by Night (2012)\n",
            "Brother (Brat) (1997)\n",
            "The Gun Runners (1958)\n",
            "People I Know (2002)\n",
            "History of a Crime (1901)\n",
            "The Villainess (2017)\n",
            "Hell's Highway (1932)\n",
            "Trespass Against Us (2017)\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}